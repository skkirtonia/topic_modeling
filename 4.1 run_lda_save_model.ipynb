{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T19:53:15.145889700Z",
     "start_time": "2024-01-09T19:53:15.092458300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Download stopwords in not downloaded\n",
    "#nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:13:15.196053100Z",
     "start_time": "2024-01-09T18:13:15.188524100Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:13:15.273302600Z",
     "start_time": "2024-01-09T18:13:15.197051Z"
    }
   },
   "outputs": [],
   "source": [
    "col_title = \"Title\"\n",
    "col_abstract = \"Abstract\"\n",
    "col_abstract_clean = \"Abstract Clean\"\n",
    "col_abstract_lemma = \"Abstract Lemma\"\n",
    "col_publication_year= \"Publication Year\"\n",
    "col_num_author = \"Number of Authors\"\n",
    "col_geographic_term = \"Geographic Term\"\n",
    "col_publisher= \"Publisher\"\n",
    "col_published_on = \"Published On\"\n",
    "col_conference = \"Conference\"\n",
    "col_conference_location = \"Conference Location\"\n",
    "col_volume = \"Volume\"\n",
    "col_issue = \"Issue\"\n",
    "col_type = \"Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:14:22.091789500Z",
     "start_time": "2024-01-09T18:14:22.066111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    },
    {
     "data": {
      "text/plain": "219"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words    = set(stopwords.words('english'))\n",
    "print(len(stop_words))\n",
    "extra_stopwords = ['use','model', 'result','study','system','vehicle','-pron-', '-PRON-', 'paper', 'author', 'method', 'propose', 'datum','have','that','can','which','datum','der','author','also','more','not','und','such','other','when','may','will','however','there','article','how','only','von','then','could','den','non','where','further','eine','auf','das','des','ein','bei','who','thus','ist','often','zur','einer','must','able','aus','zum','pre','einem',]\n",
    "stop_words = stop_words.union(set(extra_stopwords))\n",
    "len(stop_words)\n",
    "#extra_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:17:09.989086Z",
     "start_time": "2024-01-09T18:17:04.883163500Z"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.read_pickle(\"files/3.0 data_clean_text.pkl\")\n",
    "documents = table[col_abstract_lemma].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for i, r in table.iterrows():\n",
    "#     if \" ein \" in lemma:\n",
    "#         print(lemma)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sajeeb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:18:17.478737Z",
     "start_time": "2024-01-09T18:18:16.276131800Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:27:50.836453300Z",
     "start_time": "2024-01-09T18:27:50.821085600Z"
    }
   },
   "outputs": [],
   "source": [
    "# find the most frequent words and look for something that is not relevant to determining topics and add them to stopword list\n",
    "# all_words = word_tokenize(\" \".join(documents))\n",
    "# print(\"Total number of words =\", len(all_words))\n",
    "# word_count = Counter(all_words)\n",
    "# df = pd.DataFrame({\"word\":list(word_count.keys()), \"counts\":list(word_count.values())})\n",
    "# df = df.sort_values(by=\"counts\", ascending=False)\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:27:51.607328100Z",
     "start_time": "2024-01-09T18:27:51.585383700Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:30:59.379993800Z",
     "start_time": "2024-01-09T18:30:39.245369900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sajeeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['pron'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17.4 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "# max_features = top n number of words to keep\n",
    "# max_df = if 100: removes words which are in more than 100 documents_____ if .95: removes word which are in more than 95% of the documents\n",
    "# min_df = if 5: removes words which are in less than 5 documents\n",
    "# stop_words = 'english' removes stopwords in english\n",
    "# ngram_range=(1,2): if my text contains the phrase \"butter chicken\" in higer number of times: it will be considered like a word\n",
    "\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=.6, min_df=.005, stop_words=list(stop_words))\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:23:35.601201600Z",
     "start_time": "2024-01-10T01:23:35.587234800Z"
    }
   },
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:33:16.341572900Z",
     "start_time": "2024-01-09T18:32:59.414767400Z"
    }
   },
   "outputs": [],
   "source": [
    "x_traincv_df = pd.DataFrame(tf.toarray(),columns=list(tf_feature_names))\n",
    "x_traincv_df.to_parquet(\"files/4_document_word_matrix.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(tf_feature_names)):\n",
    "#    print(tf_feature_names[i]+\":\", str(array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:43:04.498255100Z",
     "start_time": "2024-01-09T18:37:08.203109300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   42.8s remaining:  3.6min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   50.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   35.9s remaining:  3.0min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   43.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   30.7s remaining:  2.6min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   38.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   31.6s remaining:  2.6min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   36.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   22.9s remaining:  1.9min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   26.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   21.2s remaining:  1.8min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   24.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 6 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   22.5s remaining:  1.9min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   25.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 7 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   17.8s remaining:  1.5min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   21.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 8 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   17.9s remaining:  1.5min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   21.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 9 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   17.1s remaining:  1.4min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   20.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   22.2s remaining:  1.9min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   25.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18.8 s\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run LDA. Topic is set to 50 based on the literature and judgement regarding transportation fields\n",
    "no_topics = 50\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=10, learning_method='batch', verbose=2,n_jobs=-1).fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files/4.0 lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump( lda, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:45:05.087117500Z",
     "start_time": "2024-01-09T18:45:05.060821300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions for printing keywords for each topic\n",
    "def get_topic_word_d_in_map(model, vectorizer, top_n=10):\n",
    "    d ={}\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        # print([(vectorizer.get_feature_names()[i], topic[i]) for i in topic.argsort()[:-top_n - 1:-1]]) \n",
    "        # print([(vectorizer.get_feature_names()[i], topic[i]) for i in topic.argsort()[:-top_n - 1:-1]]) \n",
    "        d[idx] = [(vectorizer.get_feature_names_out()[i], topic[i]) for i in topic.argsort()[:-top_n - 1:-1]]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:45:11.296839200Z",
     "start_time": "2024-01-09T18:45:05.984981200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "Topic 1:\n",
      "Topic 2:\n",
      "Topic 3:\n",
      "Topic 4:\n",
      "Topic 5:\n",
      "Topic 6:\n",
      "Topic 7:\n",
      "Topic 8:\n",
      "Topic 9:\n",
      "Topic 10:\n",
      "Topic 11:\n",
      "Topic 12:\n",
      "Topic 13:\n",
      "Topic 14:\n",
      "Topic 15:\n",
      "Topic 16:\n",
      "Topic 17:\n",
      "Topic 18:\n",
      "Topic 19:\n",
      "Topic 20:\n",
      "Topic 21:\n",
      "Topic 22:\n",
      "Topic 23:\n",
      "Topic 24:\n",
      "Topic 25:\n",
      "Topic 26:\n",
      "Topic 27:\n",
      "Topic 28:\n",
      "Topic 29:\n",
      "Topic 30:\n",
      "Topic 31:\n",
      "Topic 32:\n",
      "Topic 33:\n",
      "Topic 34:\n",
      "Topic 35:\n",
      "Topic 36:\n",
      "Topic 37:\n",
      "Topic 38:\n",
      "Topic 39:\n",
      "Topic 40:\n",
      "Topic 41:\n",
      "Topic 42:\n",
      "Topic 43:\n",
      "Topic 44:\n",
      "Topic 45:\n",
      "Topic 46:\n",
      "Topic 47:\n",
      "Topic 48:\n",
      "Topic 49:\n"
     ]
    }
   ],
   "source": [
    "#Save data for later use\n",
    "# map key = topic number; value = (word, weight)\n",
    "\n",
    "get_topic_word_d_in_map = get_topic_word_d_in_map(lda, tf_vectorizer, 100)\n",
    "with open('files/4.1 topic_word_weight.pickle', 'wb') as f:\n",
    "    pickle.dump( get_topic_word_d_in_map, f)\n",
    "\n",
    "#d = pickle.load(open(\"4_topic_word_weight.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('simulation', 12536.276611185434),\n ('analysis', 7684.32617627144),\n ('approach', 7375.683013873335),\n ('base', 6104.181681340007),\n ('dynamic', 5649.8121378440055),\n ('present', 5532.475147471269),\n ('element', 4415.1343867878495),\n ('develop', 3466.6155939688206),\n ('time', 3115.2067925192055),\n ('numerical', 3081.556272295042),\n ('tool', 2992.044379589938),\n ('modeling', 2900.0106264218052),\n ('procedure', 2747.30485677386),\n ('process', 2735.404415791768),\n ('response', 2695.189217877566),\n ('interaction', 2642.9664818657034),\n ('analytical', 2604.336164307817),\n ('complex', 2570.2813410547597),\n ('application', 2500.936406575797),\n ('function', 2392.2712954619296),\n ('domain', 2379.984046767871),\n ('finite', 2354.7299261377184),\n ('case', 2317.5557156332447),\n ('simulate', 2227.9640025422414),\n ('code', 2183.890867473433),\n ('describe', 2058.4761124231204),\n ('apply', 2017.328244058382),\n ('design', 1884.3162237763804),\n ('nonlinear', 1820.401799050032),\n ('framework', 1807.0780733390977),\n ('linear', 1773.9252258980175),\n ('obtain', 1761.7755986550962),\n ('modelling', 1756.3538762799199),\n ('development', 1732.2852693363238),\n ('order', 1726.3288921932426),\n ('software', 1705.0112329422223),\n ('behavior', 1703.455502399547),\n ('provide', 1688.368092766879),\n ('consider', 1681.6721573099346),\n ('validate', 1661.2595551542797),\n ('computational', 1650.0681012576467),\n ('new', 1599.3507623843311),\n ('technique', 1589.6138196693623),\n ('example', 1581.5142546243947),\n ('derive', 1544.8442955345474),\n ('demonstrate', 1532.2936335757438),\n ('component', 1526.03712286692),\n ('well', 1443.3911896972904),\n ('theory', 1440.6768649830967),\n ('methodology', 1440.1317122909081),\n ('solution', 1404.3678140940901),\n ('validation', 1399.8849168615732),\n ('form', 1375.6128099286555),\n ('simple', 1364.3174573423958),\n ('calculation', 1361.2055156029226),\n ('formulation', 1361.0453647753086),\n ('different', 1335.4670329313637),\n ('allow', 1318.893233598382),\n ('first', 1295.2311962014944),\n ('parameter', 1228.5435916517083),\n ('dimensional', 1226.3124919128113),\n ('discuss', 1218.919863733066),\n ('show', 1183.6388304406746),\n ('account', 1181.0822484476248),\n ('theoretical', 1165.1948245051992),\n ('represent', 1130.863124592357),\n ('implement', 1119.2149875629896),\n ('virtual', 1103.6372053837113),\n ('step', 1102.8288487101481),\n ('representation', 1051.5177374748764),\n ('introduce', 1047.5524771409328),\n ('accuracy', 1041.712310811696),\n ('give', 1038.7699846753783),\n ('comparison', 1037.04028813229),\n ('require', 1031.9031685983468),\n ('realistic', 1031.353702141383),\n ('real', 1018.4046606115271),\n ('effect', 1006.7321488090619),\n ('mathematical', 1004.4327758363996),\n ('include', 990.8765273210147),\n ('illustrate', 978.0213008703283),\n ('evaluation', 972.5308346647532),\n ('equation', 969.7211707879715),\n ('predict', 967.4656438335212),\n ('detailed', 961.8301482553965),\n ('computer', 957.1841686479808),\n ('scenario', 946.3944635463006),\n ('concept', 940.6698451176045),\n ('finally', 939.8023246641028),\n ('general', 929.1378068892866),\n ('practical', 912.4075458464704),\n ('perform', 906.6025742877),\n ('accurate', 895.2064173921417),\n ('behaviour', 892.5884025363121),\n ('experimental', 880.4465453588127),\n ('evaluate', 877.6851381752895),\n ('performance', 874.4589618964992),\n ('compare', 874.1930393638444),\n ('take', 871.5174873495527),\n ('define', 868.2907968094818)]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_word_d_in_map[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:45:31.911565400Z",
     "start_time": "2024-01-09T18:45:31.871761800Z"
    }
   },
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:57:53.337369600Z",
     "start_time": "2024-01-09T18:57:30.735359300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   19.0s remaining:  1.6min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   21.8s finished\n"
     ]
    }
   ],
   "source": [
    "# doc_topic indicates the probability of corresponding to the topic(columns)  for each document (row)\n",
    "doc_topic = lda.transform(tf)\n",
    "doc_topic_most_probable=[]\n",
    "\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    # print(\"doc: {} topic: {}\\n\".format(n,topic_most_pr))\n",
    "    doc_topic_most_probable.append(topic_most_pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(146972, 50)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:17:57.188596600Z",
     "start_time": "2024-01-10T01:17:57.159712700Z"
    }
   },
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[6, 48, 29, 4, 0, 30, 20, 29, 26, 26]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_most_probable[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:58:35.822430400Z",
     "start_time": "2024-01-09T18:58:35.807357600Z"
    }
   },
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:48:53.491912400Z",
     "start_time": "2024-01-09T18:48:53.084561200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00037736 0.00037736 0.00037736 0.03659649 0.00037736 0.00037736\n",
      " 0.23878571 0.04938398 0.00037736 0.00037736 0.00037736 0.00037736\n",
      " 0.21061178 0.10150972 0.16797232 0.00037736 0.00037736 0.00037736\n",
      " 0.00037736 0.00037736 0.00037736 0.00037736 0.00037736 0.00037736\n",
      " 0.00037736 0.00037736 0.00037736 0.00037736 0.00037736 0.00037736\n",
      " 0.00037736 0.00037736 0.00037736 0.05174566 0.00037736 0.00037736\n",
      " 0.00037736 0.00037736 0.00037736 0.00037736 0.00037736 0.00037736\n",
      " 0.00037736 0.00037736 0.00037736 0.00037736 0.00037736 0.00037736\n",
      " 0.12754528 0.00037736]\n"
     ]
    },
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(doc_topic[0])\n",
    "doc_topic_most_probable[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:49:18.653282400Z",
     "start_time": "2024-01-09T18:49:18.498551500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146972\n",
      "146972\n"
     ]
    }
   ],
   "source": [
    "print(len(doc_topic))\n",
    "print(len(doc_topic_most_probable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:49:33.170130200Z",
     "start_time": "2024-01-09T18:49:32.297093500Z"
    }
   },
   "outputs": [],
   "source": [
    "table[\"Topic Most Probable\"] = doc_topic_most_probable"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Abstract  \\\n0   Aviation provides productivity in the form of ...   \n8   Steam traction was never fully developed befor...   \n9   The Transport Infrastructure Development Corpo...   \n10  At CORE 2004 the authors presented a first pap...   \n11  Due to the daily congestion of highways, railw...   \n\n                                           Conference Conference Location  \\\n0   26th International Congress of the Aeronautica...       United States   \n8   CORE 2008, Rail; the core of integrated transp...           Australia   \n9   CORE 2008, Rail; the core of integrated transp...           Australia   \n10  CORE 2008, Rail; the core of integrated transp...           Australia   \n11  CORE 2008, Rail; the core of integrated transp...           Australia   \n\n   EISSN Geographic Term ISSN Issue Language  Number of Authors  \\\n0    NaN              []  NaN   NaN  English                  4   \n8    NaN              []  NaN  None      NaN                  1   \n9    NaN     [Australia]  NaN  None      NaN                  1   \n10   NaN     [Australia]  NaN  None      NaN                  2   \n11   NaN     [Australia]  NaN  None      NaN                  1   \n\n    Publication Year Published On Publisher Record ID  \\\n0         20080000.0          NaN       NaN   1515293   \n8         20080000.0          NaN       NaN   1301414   \n9         20080000.0          NaN       NaN   1301413   \n10        20080000.0          NaN       NaN   1301412   \n11        20080000.0          NaN       NaN   1301411   \n\n                                                Title Volume        Type  \\\n0   Payload Fuel Energy Efficiency as a Metric for...    NaN  Conference   \n8   Feasibility of steam traction for coal transpo...   None  Conference   \n9            Operational readiness - making it happen   None  Conference   \n10  Noise reducing slab track for the Epping to Ch...   None  Conference   \n11  Investigation into some design aspects of ball...   None  Conference   \n\n                                       Abstract Clean  \\\n0   Aviation provides productivity in the form of ...   \n8   Steam traction was never fully developed befor...   \n9   The Transport Infrastructure Development Corpo...   \n10  At CORE the authors presented a first paper on...   \n11  Due to the daily congestion of highways railwa...   \n\n                                       Abstract Lemma  Topic Most Probable  \n0   aviation provide productivity form transport p...                    6  \n8   steam traction be never fully develop be super...                   48  \n9   transport infrastructure development corporati...                   29  \n10  core author present first paper control noise ...                    4  \n11  daily congestion highway railway have become m...                    0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Abstract</th>\n      <th>Conference</th>\n      <th>Conference Location</th>\n      <th>EISSN</th>\n      <th>Geographic Term</th>\n      <th>ISSN</th>\n      <th>Issue</th>\n      <th>Language</th>\n      <th>Number of Authors</th>\n      <th>Publication Year</th>\n      <th>Published On</th>\n      <th>Publisher</th>\n      <th>Record ID</th>\n      <th>Title</th>\n      <th>Volume</th>\n      <th>Type</th>\n      <th>Abstract Clean</th>\n      <th>Abstract Lemma</th>\n      <th>Topic Most Probable</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aviation provides productivity in the form of ...</td>\n      <td>26th International Congress of the Aeronautica...</td>\n      <td>United States</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>English</td>\n      <td>4</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1515293</td>\n      <td>Payload Fuel Energy Efficiency as a Metric for...</td>\n      <td>NaN</td>\n      <td>Conference</td>\n      <td>Aviation provides productivity in the form of ...</td>\n      <td>aviation provide productivity form transport p...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Steam traction was never fully developed befor...</td>\n      <td>CORE 2008, Rail; the core of integrated transp...</td>\n      <td>Australia</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1301414</td>\n      <td>Feasibility of steam traction for coal transpo...</td>\n      <td>None</td>\n      <td>Conference</td>\n      <td>Steam traction was never fully developed befor...</td>\n      <td>steam traction be never fully develop be super...</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The Transport Infrastructure Development Corpo...</td>\n      <td>CORE 2008, Rail; the core of integrated transp...</td>\n      <td>Australia</td>\n      <td>NaN</td>\n      <td>[Australia]</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1301413</td>\n      <td>Operational readiness - making it happen</td>\n      <td>None</td>\n      <td>Conference</td>\n      <td>The Transport Infrastructure Development Corpo...</td>\n      <td>transport infrastructure development corporati...</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>At CORE 2004 the authors presented a first pap...</td>\n      <td>CORE 2008, Rail; the core of integrated transp...</td>\n      <td>Australia</td>\n      <td>NaN</td>\n      <td>[Australia]</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1301412</td>\n      <td>Noise reducing slab track for the Epping to Ch...</td>\n      <td>None</td>\n      <td>Conference</td>\n      <td>At CORE the authors presented a first paper on...</td>\n      <td>core author present first paper control noise ...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Due to the daily congestion of highways, railw...</td>\n      <td>CORE 2008, Rail; the core of integrated transp...</td>\n      <td>Australia</td>\n      <td>NaN</td>\n      <td>[Australia]</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1301411</td>\n      <td>Investigation into some design aspects of ball...</td>\n      <td>None</td>\n      <td>Conference</td>\n      <td>Due to the daily congestion of highways railwa...</td>\n      <td>daily congestion highway railway have become m...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:49:40.006433900Z",
     "start_time": "2024-01-09T18:49:39.677398100Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:50:20.982099500Z",
     "start_time": "2024-01-09T18:50:20.902019600Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_topic_all_topic=[]\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    doc_topic_all_topic.append(doc_topic[n])\n",
    "table[\"Topic All\"] = doc_topic_all_topic"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Abstract  \\\n0   Aviation provides productivity in the form of ...   \n8   Steam traction was never fully developed befor...   \n9   The Transport Infrastructure Development Corpo...   \n10  At CORE 2004 the authors presented a first pap...   \n11  Due to the daily congestion of highways, railw...   \n\n                                           Conference Conference Location  \\\n0   26th International Congress of the Aeronautica...       United States   \n8   CORE 2008, Rail; the core of integrated transp...           Australia   \n9   CORE 2008, Rail; the core of integrated transp...           Australia   \n10  CORE 2008, Rail; the core of integrated transp...           Australia   \n11  CORE 2008, Rail; the core of integrated transp...           Australia   \n\n   EISSN Geographic Term ISSN Issue Language  Number of Authors  \\\n0    NaN              []  NaN   NaN  English                  4   \n8    NaN              []  NaN  None      NaN                  1   \n9    NaN     [Australia]  NaN  None      NaN                  1   \n10   NaN     [Australia]  NaN  None      NaN                  2   \n11   NaN     [Australia]  NaN  None      NaN                  1   \n\n    Publication Year Published On Publisher Record ID  \\\n0         20080000.0          NaN       NaN   1515293   \n8         20080000.0          NaN       NaN   1301414   \n9         20080000.0          NaN       NaN   1301413   \n10        20080000.0          NaN       NaN   1301412   \n11        20080000.0          NaN       NaN   1301411   \n\n                                                Title Volume        Type  \\\n0   Payload Fuel Energy Efficiency as a Metric for...    NaN  Conference   \n8   Feasibility of steam traction for coal transpo...   None  Conference   \n9            Operational readiness - making it happen   None  Conference   \n10  Noise reducing slab track for the Epping to Ch...   None  Conference   \n11  Investigation into some design aspects of ball...   None  Conference   \n\n                                       Abstract Clean  \\\n0   Aviation provides productivity in the form of ...   \n8   Steam traction was never fully developed befor...   \n9   The Transport Infrastructure Development Corpo...   \n10  At CORE the authors presented a first paper on...   \n11  Due to the daily congestion of highways railwa...   \n\n                                       Abstract Lemma  Topic Most Probable  \\\n0   aviation provide productivity form transport p...                    6   \n8   steam traction be never fully develop be super...                   48   \n9   transport infrastructure development corporati...                   29   \n10  core author present first paper control noise ...                    4   \n11  daily congestion highway railway have become m...                    0   \n\n                                            Topic All  \n0   [0.00037735849056614885, 0.0003773584905661488...  \n8   [0.00017699115044253716, 0.0001769911504425371...  \n9   [0.0005128205128206213, 0.0005128205128206213,...  \n10  [0.06569086186281409, 0.126931094088743, 0.000...  \n11  [0.29262132271997376, 0.04042160754206258, 0.0...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Abstract</th>\n      <th>Conference</th>\n      <th>Conference Location</th>\n      <th>EISSN</th>\n      <th>Geographic Term</th>\n      <th>ISSN</th>\n      <th>Issue</th>\n      <th>Language</th>\n      <th>Number of Authors</th>\n      <th>Publication Year</th>\n      <th>Published On</th>\n      <th>Publisher</th>\n      <th>Record ID</th>\n      <th>Title</th>\n      <th>Volume</th>\n      <th>Type</th>\n      <th>Abstract Clean</th>\n      <th>Abstract Lemma</th>\n      <th>Topic Most Probable</th>\n      <th>Topic All</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aviation provides productivity in the form of ...</td>\n      <td>26th International Congress of the Aeronautica...</td>\n      <td>United States</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>English</td>\n      <td>4</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1515293</td>\n      <td>Payload Fuel Energy Efficiency as a Metric for...</td>\n      <td>NaN</td>\n      <td>Conference</td>\n      <td>Aviation provides productivity in the form of ...</td>\n      <td>aviation provide productivity form transport p...</td>\n      <td>6</td>\n      <td>[0.00037735849056614885, 0.0003773584905661488...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Steam traction was never fully developed befor...</td>\n      <td>CORE 2008, Rail; the core of integrated transp...</td>\n      <td>Australia</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1301414</td>\n      <td>Feasibility of steam traction for coal transpo...</td>\n      <td>None</td>\n      <td>Conference</td>\n      <td>Steam traction was never fully developed befor...</td>\n      <td>steam traction be never fully develop be super...</td>\n      <td>48</td>\n      <td>[0.00017699115044253716, 0.0001769911504425371...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The Transport Infrastructure Development Corpo...</td>\n      <td>CORE 2008, Rail; the core of integrated transp...</td>\n      <td>Australia</td>\n      <td>NaN</td>\n      <td>[Australia]</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1301413</td>\n      <td>Operational readiness - making it happen</td>\n      <td>None</td>\n      <td>Conference</td>\n      <td>The Transport Infrastructure Development Corpo...</td>\n      <td>transport infrastructure development corporati...</td>\n      <td>29</td>\n      <td>[0.0005128205128206213, 0.0005128205128206213,...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>At CORE 2004 the authors presented a first pap...</td>\n      <td>CORE 2008, Rail; the core of integrated transp...</td>\n      <td>Australia</td>\n      <td>NaN</td>\n      <td>[Australia]</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1301412</td>\n      <td>Noise reducing slab track for the Epping to Ch...</td>\n      <td>None</td>\n      <td>Conference</td>\n      <td>At CORE the authors presented a first paper on...</td>\n      <td>core author present first paper control noise ...</td>\n      <td>4</td>\n      <td>[0.06569086186281409, 0.126931094088743, 0.000...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Due to the daily congestion of highways, railw...</td>\n      <td>CORE 2008, Rail; the core of integrated transp...</td>\n      <td>Australia</td>\n      <td>NaN</td>\n      <td>[Australia]</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>20080000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1301411</td>\n      <td>Investigation into some design aspects of ball...</td>\n      <td>None</td>\n      <td>Conference</td>\n      <td>Due to the daily congestion of highways railwa...</td>\n      <td>daily congestion highway railway have become m...</td>\n      <td>0</td>\n      <td>[0.29262132271997376, 0.04042160754206258, 0.0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:50:30.407541300Z",
     "start_time": "2024-01-09T18:50:30.122838900Z"
    }
   },
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# some topics are related to group of words which are a cluster of academic words we replace the topic of those document with the second most probable topic\n",
    "def assignSecondTopic(row):\n",
    "    topic=row[\"Topic Most Probable\"]\n",
    "    if row[\"Topic Most Probable\"] in [27, 34, 49]:\n",
    "        secondMost = np.where(row[\"Topic All\"]==np.sort(row[\"Topic All\"])[-2])\n",
    "        topic =  secondMost\n",
    "    return topic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "table[\"Topic Most Probable\"]  = table.apply(assignSecondTopic, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_parquet(\"files/4.0 data_with_topic.parquet\")\n",
    "table.to_csv(\"files/4.0 data_with_topic.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
